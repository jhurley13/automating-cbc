{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test-EBird-Dec2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "Examine bulk data from eBird for December 2020\n",
    "\n",
    "https://ebird.org/science/use-ebird-data/download-ebird-data-products  \n",
    "https://ebird.org/data/download  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# warnings.simplefilter('always') # 'error' to break\\n\", \\\"always\\\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module='geopandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('common')\n",
    "sys.path.append('textextractor')\n",
    "sys.path.append('taxonomy')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely import geometry\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common_jupyter\n",
    "\n",
    "# https://medium.com/@rrfd/cookiecutter-data-science-organize-your-projects-atom-and-jupyter-2be7862f487e\n",
    "from common_paths import *\n",
    "\n",
    "from local_translation_context import LocalTranslationContext\n",
    "from taxonomy import Taxonomy\n",
    "from ebird_extras import EBirdExtra\n",
    "from parameters import Parameters\n",
    "\n",
    "from count_day_tasks import summarize_checklists, create_full_circle_summary, get_participants, \\\n",
    "    subids_for_pete_dunten, add_bob_hirt, get_personal_checklist_details\n",
    "\n",
    "from datetime_manipulation import create_count_week\n",
    "# from checklist_manipulation import create_checklist_meta\n",
    "\n",
    "# from write_final_checklist import write_final_checklist_spreadsheet, excel_columns, \\\n",
    "#     sheet_info_for_party_efforts, sheet_info_for_party_details, sheet_info_for_rarities, sheet_info_for_filers\n",
    "# from autoparty import sheet_info_for_autoparty, generate_autoparty\n",
    "from locations_map import create_coverage_map, create_potential_duplicates_map\n",
    "from utilities_kml import build_geodata, build_location_data, update_geo_data_with_clustering, build_location_meta\n",
    "from ebird_visits import transform_visits, visits_in_circle\n",
    "# from utilities_clustering import generate_cluster_table, plot_elbow_curve\n",
    "# from filers_matrix import create_filers_matrix\n",
    "from checklist_manipulation import create_checklist_meta, write_checklist_meta, find_location_near_duplicates\n",
    "# from checklist_manipulation import construct_team_details, construct_team_efforts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visits_in_circle(ebirders, geo_data, circle_code, visits):\n",
    "    # Also filters by participants\n",
    "    circle_geometry = geo_data[(geo_data.CircleCode == circle_code) &\n",
    "                               (geo_data.type == 'circle')].geometry.values[0]\n",
    "\n",
    "    # Note that by construction, visits only contains data for dates we care about\n",
    "    # so we don't need to filter for that. We pass them to get_details grouped by date though.\n",
    "    mask = [pt.within(circle_geometry) for pt in visits.geometry.values]\n",
    "    if ebirders is not None:\n",
    "        mask &= visits.Name.isin(ebirders)\n",
    "    visits_of_interest = visits[mask].sort_values(by=['locId'])\n",
    "\n",
    "    return visits_of_interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.parser as parser\n",
    "\n",
    "def normalize_time_for_visits(time_str: str) -> str:\n",
    "    # visits has e.g. obsTime 17:23, with no seconds\n",
    "    xtime = parser.parse(time_str).strftime('%H:%M')\n",
    "\n",
    "    return xtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bulk_data() -> pd.DataFrame():\n",
    "    bulk_data = None\n",
    "    # This is really specific, so hardwire paths for now\n",
    "    bulk_data_dir = raw_data_path / 'ebd_US-CA_202012_202101_prv_relDec-2020'\n",
    "    bulk_data_path = bulk_data_dir / 'ebd_US-CA_202012_202101_prv_relDec-2020.txt'\n",
    "    if not bulk_data_path.exists():\n",
    "        return None\n",
    "    \n",
    "    bulk_data = pd.read_csv(bulk_data_path, dtype=str, header=0, sep='\\t', low_memory=False).fillna('')\n",
    "    provisional_data_path = bulk_data_dir / 'ebd_US-CA_202012_202101_prv_relDec-2020_provisional.txt'\n",
    "    if provisional_data_path.exists():\n",
    "        prov_data  = pd.read_csv(provisional_data_path, dtype=str, header=0, sep='\\t', low_memory=False).fillna('')\n",
    "        bulk_data = pd.concat([bulk_data, prov_data], axis=0, ignore_index=True)\n",
    "        \n",
    "    return bulk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "def find_missing_subids(visits: pd.DataFrame, bulk_data: Optional[pd.DataFrame], \n",
    "                        xdates: List[str], region_codes: List[str]):\n",
    "    if bulk_data is None:\n",
    "        return []\n",
    "    mask = (bulk_data['OBSERVATION DATE'].isin(xdates)) & (bulk_data['COUNTY CODE'].isin(region_codes))\n",
    "    bulk_subids = set(bulk_data[mask]['SAMPLING EVENT IDENTIFIER'].values)\n",
    "    base_subids = set(visits.subId.values)\n",
    "    \n",
    "    return sorted(list(bulk_subids - set(base_subids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_basic_dataset(visits: pd.DataFrame, xdates: List[str], region_codes: List[str]) -> pd.DataFrame:\n",
    "    # Consult Basic Dataset (EBD) bulk data from eBird to find missing subIds\n",
    "    # Append records to visits if any are found\n",
    "    # Takes about 13s to load BDS for Dec 2020\n",
    "    bulk_data = load_bulk_data()\n",
    "    if bulk_data is None:\n",
    "        return visits\n",
    "\n",
    "    missing_subids = find_missing_subids(visits, bulk_data, xdates, region_codes)\n",
    "    bds = bulk_data[bulk_data['SAMPLING EVENT IDENTIFIER'].isin(missing_subids)].copy().reset_index(drop=True)\n",
    "    if bds.empty:\n",
    "        return visits\n",
    "    \n",
    "    # Names match those in visits\n",
    "    new_col_names = {\n",
    "        'LOCALITY ID': 'locId', 'SAMPLING EVENT IDENTIFIER': 'subId', 'OBSERVER ID': 'Name',\n",
    "         'OBSERVATION DATE': 'obsDt',   'TIME OBSERVATIONS STARTED': 'obsTime',\n",
    "        'LOCALITY': 'loc_name',  'LATITUDE': 'latitude', 'LONGITUDE': 'longitude', \n",
    "    }\n",
    "    bds.rename(columns=new_col_names, inplace=True)\n",
    "\n",
    "    numSpecies_df = bds.groupby(['subId']).size().reset_index(name='numSpecies').sort_values(by=['subId'])\n",
    "\n",
    "    bds = bds.drop_duplicates(['subId', 'obsDt', 'obsTime', 'latitude', 'longitude']).reset_index(drop=True)\n",
    "\n",
    "    bds['numSpecies'] = numSpecies_df.numSpecies.values\n",
    "    bds.obsTime = bds.obsTime.apply(normalize_time_for_visits)\n",
    "\n",
    "    new_col_order = ['locId', 'subId', 'Name', 'numSpecies', 'obsDt', 'obsTime', 'loc_name', 'latitude', 'longitude']\n",
    "    bds = bds[new_col_order].sort_values(by=['subId']).reset_index(drop=True)\n",
    "\n",
    "    for col in ['latitude', 'longitude']:\n",
    "        bds[col] = bds[col].apply(pd.to_numeric).fillna(0).astype(float)\n",
    "\n",
    "    vgeometry = [Point(x, y) for x, y in zip(bds.longitude, bds.latitude)]  # Longitude first\n",
    "    bds['geometry'] = vgeometry\n",
    "\n",
    "    # We could fix 'Name' with 'userDisplayName' field from get_details, but not important here\n",
    "\n",
    "    return pd.concat([visits, bds], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializations\n",
    "print(f'Start : {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "print('Initializing...')\n",
    "\n",
    "create_project_paths()\n",
    "\n",
    "# Overrides - Credentials\n",
    "# See Samples/eBirdCredentials.yml for an example\n",
    "my_credentials_storage_path = Path('/Volumes/TSecure3/other/')\n",
    "eBirdCredential_path = my_credentials_storage_path / 'eBirdCredentials.yml'\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# Override - This will find the correct parameter file out of many in Local folder\n",
    "# -----------------------------------------------------------------------------------------\n",
    "circle_prefix = 'CACR-2020-'\n",
    "\n",
    "# Parameters\n",
    "parameters = Parameters(local_parameters_path, system_parameters_path, circle_prefix, False)\n",
    "\n",
    "local_translation_context = LocalTranslationContext(local_parameters_path, system_parameters_path)\n",
    "local_translation_context.reload() # DEBUG; allows test/edit cycle without restarting kernel (singleton)\n",
    "\n",
    "# Singletons\n",
    "country = parameters.parameters.get('NationalCode', 'US')\n",
    "ebird_extra = EBirdExtra(eBirdCredential_path, cache_path, country)\n",
    "taxonomy = Taxonomy(cache_path, ebird_extra)\n",
    "\n",
    "# Convenient Parameters\n",
    "circle_code = parameters.parameters.get('CircleAbbrev', 'XXXX')\n",
    "date_of_count = parameters.parameters['CountDate']\n",
    "count_week_start = parameters.parameters.get('CountWeekStart', date_of_count)\n",
    "count_week_end = parameters.parameters.get('CountWeekEnd', date_of_count)\n",
    "region_codes = [xs.strip() for xs in parameters.parameters['eBirdRegion'].split(',')]\n",
    "\n",
    "# Will drop any dates in the future\n",
    "count_week = create_count_week(count_week_start, count_week_end)\n",
    "\n",
    "print('Initialization complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    geo_data = build_geodata(parameters)\n",
    "    \n",
    "    # May need bootstrapping\n",
    "    participants = get_participants(circle_prefix)\n",
    "\n",
    "    xdates = [date_of_count] #if count_day_only else count_week\n",
    "    visits = ebird_extra.get_visits_for_dates(region_codes, xdates)\n",
    "    print(f'Checklists filed in count circle: {visits.shape[0]}')\n",
    "    visits = transform_visits(visits)\n",
    "    \n",
    "    # Add bulk data extras here\n",
    "    visits = use_basic_dataset(visits, xdates, region_codes)\n",
    "    print(f'Checklists after basic dataset: {visits.shape[0]}')\n",
    "\n",
    "    visits_of_interest = visits_in_circle(participants, geo_data, circle_code, visits)\n",
    "    visits_of_interest.shape, visits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bulk_data = load_bulk_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_missing_subids(visits, bulk_data, date_of_count, region_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {raw_data_path / 'ebd_US-CA_202012_202101_prv_relDec-2020'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebird_dec2020_path = raw_data_path / 'ebd_US-CA-085_202012_202101_prv_relDec-2020'\n",
    "!ls {ebird_dec2020_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dec2020_path = ebird_dec2020_path / 'ebd_US-CA-085_202012_202101_prv_relDec-2020.txt'\n",
    "raw_dec2020 = pd.read_csv(raw_dec2020_path, dtype=str, header=0, sep='\\t',\n",
    "                                         low_memory=False).fillna('')\n",
    "raw_dec2020.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dec2020.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dec2020.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cacr_subset = raw_dec2020[raw_dec2020['OBSERVATION DATE']==date_of_count].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ', '.join(sorted(list(set(casj_subset['SAMPLING EVENT IDENTIFIER'].values) - set(visits.subId.values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(cacr_subset['SAMPLING EVENT IDENTIFIER'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "', '.join(sorted(list(set(cacr_subset['SAMPLING EVENT IDENTIFIER'].values) - set(visits.subId.values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_geo_columns = ['LOCALITY', 'LOCALITY ID', \n",
    "                   'LATITUDE', 'LONGITUDE', 'OBSERVATION DATE',\n",
    "                  'TIME OBSERVATIONS STARTED', 'SAMPLING EVENT IDENTIFIER', \n",
    "                   'OBSERVER ID', 'OBSERVATION COUNT']\n",
    "count_subset = raw_dec2020[raw_dec2020['OBSERVATION DATE']==date_of_count].copy()\n",
    "count_geo = count_subset[raw_geo_columns].copy().drop_duplicates(['SAMPLING EVENT IDENTIFIER']).reset_index(drop=True)\n",
    "\n",
    "count_geo.rename(columns={'LOCALITY': 'loc_name', 'LOCALITY ID': 'locId', \n",
    "        'LATITUDE': 'latitude', 'LONGITUDE': 'longitude', 'OBSERVATION DATE': 'obsDt',\n",
    "       'TIME OBSERVATIONS STARTED': 'obsTime', 'SAMPLING EVENT IDENTIFIER': 'subId',\n",
    "                         'OBSERVER ID': 'Name', 'OBSERVATION COUNT': 'numSpecies'}, inplace=True)\n",
    "\n",
    "new_col_order = ['locId', 'subId', 'obsDt', 'obsTime', 'loc_name', 'latitude', 'longitude', 'Name', 'numSpecies']\n",
    "count_geo = count_geo[new_col_order]\n",
    "\n",
    "for col in ['latitude', 'longitude']:\n",
    "    count_geo[col] = count_geo[col].apply(pd.to_numeric).fillna(0).astype(float)\n",
    "\n",
    "vgeometry = [Point(x, y) for x, y in zip(count_geo.longitude, count_geo.latitude)]  # Longitude first\n",
    "count_geo['geometry'] = vgeometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_geo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_geo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_of_interest.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_of_interest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_geo.rename(columns={'LOCALITY': 'loc_name', 'LOCALITY ID': 'locId', \n",
    "#         'LATITUDE': 'latitude', 'LONGITUDE': 'longitude', 'OBSERVATION DATE': 'obsDt',\n",
    "#        'TIME OBSERVATIONS STARTED': 'obsTime', 'SAMPLING EVENT IDENTIFIER': 'subId',\n",
    "#                          'OBSERVER ID': 'Name', 'OBSERVATION COUNT': 'numSpecies'}, inplace=True)\n",
    "\n",
    "# new_col_order = ['locId', 'subId', 'obsDt', 'obsTime', 'loc_name', 'latitude', 'longitude', 'Name', 'numSpecies']\n",
    "# count_geo = count_geo[new_col_order]\n",
    "\n",
    "# for col in ['latitude', 'longitude']:\n",
    "#     count_geo[col] = count_geo[col].apply(pd.to_numeric).fillna(0).astype(int)\n",
    "\n",
    "# vgeometry = [Point(x, y) for x, y in zip(count_geo.longitude, count_geo.latitude)]  # Longitude first\n",
    "# count_geo['geometry'] = vgeometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voi = visits_in_circle(None, geo_data, circle_code, count_geo)\n",
    "voi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circle_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circle_geometry = geo_data[(geo_data.CircleCode == circle_code) &\n",
    "                               (geo_data.type == 'circle')].geometry.values[0]\n",
    "\n",
    "# # Note that by construction, visits only contains data for dates we care about\n",
    "# # so we don't need to filter for that. We pass them to get_details grouped by date though.\n",
    "mask = [pt.within(circle_geometry) for pt in count_geo.geometry.values]\n",
    "# if ebirders is not None:\n",
    "#     mask &= visits.Name.isin(ebirders)\n",
    "# visits_of_interest = visits[mask].sort_values(by=['locId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_geo.geometry.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([circle_geometry.contains(pt) for pt in count_geo.geometry.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_geo.geometry.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_geo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_coverage_map(count_geo, parameters, geo_data, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "', '.join(sorted(list(set(voi.subId.values) - set(visits_of_interest.subId.values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(['S77994527, S77994556, S77995886, S78003733, S78011449, S78012810, S78016009, S78035225, S78036994, S78037576, S78038313'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dec2020.APPROVED.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dec2020['HAS MEDIA'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to eBird API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_visits = ebird_extra.ebird_client.get_visits('US-CA-085', date_of_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_visits.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(raw_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['locId', 'subId', 'userDisplayName', 'numSpecies', 'obsDt', 'obsTime', 'subID', 'loc']\n",
    "pd.DataFrame(raw_visits).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdf = pd.DataFrame(raw_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdf.iloc[0]['loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dec2020.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subid = 'S78043369'\n",
    "s78043369 = ebird_extra.ebird_client.get_checklist(subid)\n",
    "s78043369 #.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowdict = s78043369.copy()\n",
    "obs = rowdict['obs']\n",
    "del rowdict['obs']\n",
    "rowdict.update(obs[0])\n",
    "rowdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(rowdict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dec2020.columns.to_csv('/tmp/raw_dec2020_columns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(list(rowdict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colmap = pd.DataFrame()\n",
    "colmap['raw'] = list(raw_dec2020.columns)\n",
    "colmap['api'] = pd.Series(list(rowdict.keys())).pad(limit=len(list(raw_dec2020.columns)))\n",
    "colmap.to_csv('/tmp/raw_dec2020_columns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The date in the raw data dump is most similar to the data returned from the eBird API\n",
    "# get_details. Our main purpose here is to find any missing subIds. We could morph the\n",
    "# data in the bulk dump, but for the small number of missing records, it is easier to \n",
    "# just add them to visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dec2020['COUNTY CODE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_subids = visits.subId.values\n",
    "len(base_subids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_subids = set(raw_dec2020[raw_dec2020['OBSERVATION DATE']==date_of_count]['SAMPLING EVENT IDENTIFIER'].values)\n",
    "len(bulk_subids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(set(base_subids) ^ bulk_subids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(bulk_subids - set(base_subids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ebird.org/checklist/S79107962\n",
    "sorted(list(set(base_subids) - bulk_subids ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_missing_subids(visits, raw_dec2020, date_of_count, region_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dec2020.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_geo_columns = ['LOCALITY', 'LOCALITY ID', \n",
    "                   'LATITUDE', 'LONGITUDE', 'OBSERVATION DATE',\n",
    "                  'TIME OBSERVATIONS STARTED', 'SAMPLING EVENT IDENTIFIER', \n",
    "                   'OBSERVER ID', 'OBSERVATION COUNT']\n",
    "count_subset = raw_dec2020[raw_dec2020['OBSERVATION DATE']==date_of_count].copy()\n",
    "count_geo = count_subset[raw_geo_columns].copy().drop_duplicates(['SAMPLING EVENT IDENTIFIER']).reset_index(drop=True)\n",
    "\n",
    "count_geo.rename(columns={'LOCALITY': 'loc_name', 'LOCALITY ID': 'locId', \n",
    "        'LATITUDE': 'latitude', 'LONGITUDE': 'longitude', 'OBSERVATION DATE': 'obsDt',\n",
    "       'TIME OBSERVATIONS STARTED': 'obsTime', 'SAMPLING EVENT IDENTIFIER': 'subId',\n",
    "                         'OBSERVER ID': 'Name', 'OBSERVATION COUNT': 'numSpecies'}, inplace=True)\n",
    "\n",
    "new_col_order = ['locId', 'subId', 'obsDt', 'obsTime', 'loc_name', 'latitude', 'longitude', 'Name', 'numSpecies']\n",
    "count_geo = count_geo[new_col_order]\n",
    "\n",
    "for col in ['latitude', 'longitude']:\n",
    "    count_geo[col] = count_geo[col].apply(pd.to_numeric).fillna(0).astype(float)\n",
    "\n",
    "vgeometry = [Point(x, y) for x, y in zip(count_geo.longitude, count_geo.latitude)]  # Longitude first\n",
    "count_geo['geometry'] = vgeometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we make fake visits entries with bulk data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Dataset (EBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_subids = find_missing_subids(visits, bulk_data, date_of_count, region_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bds = bulk_data[bulk_data['SAMPLING EVENT IDENTIFIER'].isin(missing_subids)].copy().reset_index()\n",
    "bds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bds.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bds.groupby(['SAMPLING EVENT IDENTIFIER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bds.groupby(['SAMPLING EVENT IDENTIFIER']).size().reset_index(name='numSpecies').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, (subid, grp) in enumerate(bds.groupby(['SAMPLING EVENT IDENTIFIER'])):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bds = bulk_data[bulk_data['SAMPLING EVENT IDENTIFIER'].isin(missing_subids)].copy().reset_index(drop=True)\n",
    "\n",
    "# Names match those in visits\n",
    "new_col_names = {\n",
    "    'LOCALITY ID': 'locId', 'SAMPLING EVENT IDENTIFIER': 'subId', 'OBSERVER ID': 'Name',\n",
    "     'OBSERVATION DATE': 'obsDt',   'TIME OBSERVATIONS STARTED': 'obsTime',\n",
    "    'LOCALITY': 'loc_name',  'LATITUDE': 'latitude', 'LONGITUDE': 'longitude', \n",
    "        \n",
    "                         'OBSERVATION COUNT': 'numSpecies'\n",
    "}\n",
    "bds.rename(columns=new_col_names, inplace=True)\n",
    "\n",
    "numSpecies_df = bds.groupby(['subId']).size().reset_index(name='numSpecies').sort_values(by=['subId'])\n",
    "\n",
    "new_col_order = ['locId', 'subId', 'Name', 'numSpecies', 'obsDt', 'obsTime', 'loc_name', 'latitude', 'longitude']\n",
    "bds = bds[new_col_order].sort_values(by=['subId']).reset_index(drop=True)\n",
    "\n",
    "bds = bds.drop_duplicates(['subId', 'obsDt', 'obsTime', 'latitude', 'longitude']).reset_index(drop=True)\n",
    "\n",
    "bds['numSpecies'] = numSpecies_df.numSpecies.values\n",
    "bds.obsTime = bds.obsTime.apply(normalize_time_for_visits)\n",
    "\n",
    "for col in ['latitude', 'longitude']:\n",
    "    bds[col] = bds[col].apply(pd.to_numeric).fillna(0).astype(float)\n",
    "\n",
    "vgeometry = [Point(x, y) for x, y in zip(bds.longitude, bds.latitude)]  # Longitude first\n",
    "bds['geometry'] = vgeometry\n",
    "\n",
    "# We could fix 'Name' with 'userDisplayName' field from get_details, but not important here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missing_subids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, (subid, grp) in enumerate(bds.groupby(['subId', 'obsDt', 'obsTime', 'latitude', 'longitude'])):\n",
    "    display(grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bds.obsTime.apply(normalize_time_for_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subid = 'S77994527'\n",
    "s77994527 = ebird_extra.ebird_client.get_checklist(subid)\n",
    "s77994527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py387",
   "language": "python",
   "name": "py387"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
